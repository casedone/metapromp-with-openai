{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./openai_key.txt', 'r') as f:\n",
    "    openai_key = f.read()\n",
    "    \n",
    "if openai_key==\"\":\n",
    "    warnings.warn(\"You need to provide correct OpenAI API key in `openai_key.txt` file.\")\n",
    "    \n",
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./metaprompt_text.txt', 'r') as f:\n",
    "    metaprompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inputs_field(inputs: str) -> List:\n",
    "    \"\"\"Split at comma, trim, replace blank with _, and capitalize\n",
    "    \"\"\"\n",
    "    variables = []\n",
    "    if inputs != \"\":\n",
    "        inputs = inputs.split(\",\")\n",
    "        for input in inputs:\n",
    "            variables.append(input.strip().replace(\" \",\"_\").upper())\n",
    "            \n",
    "    # from Anthropic\n",
    "    variable_string = \"\"\n",
    "    for variable in variables:\n",
    "        variable_string += \"\\n{$\" + variable.upper() + \"}\"\n",
    "        \n",
    "    assistant_partial = \"<Inputs>\"\n",
    "    if variable_string:\n",
    "        assistant_partial += variable_string + \"\\n</Inputs>\\n<Instructions Structure>\"\n",
    "    \n",
    "    return assistant_partial\n",
    "\n",
    "def process_task_field(task: str) -> str:\n",
    "    prompt = metaprompt.replace(\"{{TASK}}\", task)\n",
    "    return prompt\n",
    "\n",
    "def create_message(prompt, assistant_partial):\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_partial},\n",
    "    ]\n",
    "    return history\n",
    "\n",
    "######\n",
    "def extract_between_tags(tag: str, string: str, strip: bool = False) -> list[str]:\n",
    "    ext_list = re.findall(f\"<{tag}>(.+?)</{tag}>\", string, re.DOTALL)\n",
    "    if strip:\n",
    "        ext_list = [e.strip() for e in ext_list]\n",
    "    return ext_list\n",
    "\n",
    "def remove_empty_tags(text):\n",
    "    return re.sub(r'\\n<(\\w+)>\\s*</\\1>\\n', '', text, flags=re.DOTALL)\n",
    "\n",
    "def strip_last_sentence(text):\n",
    "    sentences = text.split('. ')\n",
    "    if sentences[-1].startswith(\"Let me know\"):\n",
    "        sentences = sentences[:-1]\n",
    "        result = '. '.join(sentences)\n",
    "        if result and not result.endswith('.'):\n",
    "            result += '.'\n",
    "        return result\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def extract_prompt(metaprompt_response, tag=\"Instructions\") -> str:\n",
    "    ### modified\n",
    "    extracted = extract_between_tags(tag, metaprompt_response)\n",
    "    if len(extracted)==0: # empty list\n",
    "        return \"<not found>\"\n",
    "    else:\n",
    "        between_tags = extracted[0]\n",
    "        return between_tags[:1000] + strip_last_sentence(remove_empty_tags(remove_empty_tags(between_tags[1000:]).strip()).strip())\n",
    "\n",
    "def extract_variables(prompt):\n",
    "    pattern = r'{([^}]+)}'\n",
    "    variables = re.findall(pattern, prompt)\n",
    "    return set(variables)\n",
    "\n",
    "\n",
    "####### MAIN FUNC HERE\n",
    "\n",
    "def run(task, inputs):\n",
    "    if task == \"\":\n",
    "        output = \"Error: Task cannot be empty.\"\n",
    "    else:\n",
    "        assistant_partial = process_inputs_field(inputs)\n",
    "        prompt = process_task_field(task)\n",
    "        history = create_message(prompt, assistant_partial)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            max_tokens=4096,\n",
    "            messages=history,\n",
    "            temperature=0\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "    \n",
    "        # output = tempt\n",
    "        extracted_inst_struct = extract_prompt(output, tag=\"Instructions Structure\")\n",
    "        extracted_prompt_template = extract_prompt(output, tag=\"Instructions\")\n",
    "    return extracted_inst_struct, extracted_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    demo.close()\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"Prompt Generator\n",
    "                   ================\n",
    "                   This is powered by **metaprompt** from Anthropic and OpenAI's **GPT-4o**.\n",
    "                   How to use it:\n",
    "                   - Write your task in the Task box.\n",
    "                   - Provide necessary inputs if the task needs in the Inputs box.\n",
    "                   \n",
    "                    **Example**\n",
    "                    \n",
    "                    - Task: Find sentiment of the customer review\n",
    "                    - Inputs customer review\n",
    "                \"\"\")\n",
    "    with gr.Row() as r1:\n",
    "        with gr.Column() as r1c1:\n",
    "            task = gr.Text(label=\"Task\", lines=5, placeholder=\"create a structure of my blog about workout for me\")\n",
    "        with gr.Column() as r1c2:\n",
    "            inputs = gr.Text(label=\"Inputs (comma seperated)\", lines=5, placeholder= \"initial idea, specific terms\")\n",
    "    with gr.Row() as r2:\n",
    "        bttn = gr.Button(value=\"Run\", variant=\"primary\")\n",
    "    with gr.Row() as r3:\n",
    "        with gr.Column(scale=1) as r3c1:\n",
    "            gr.Markdown(\"⬇️ **Instructions Structure**\")\n",
    "            inst_struc = gr.Markdown()\n",
    "        with gr.Column(scale=4) as r3c2:\n",
    "            gr.Markdown(\"⬇️ **Recommended Prompt**\")\n",
    "            inst = gr.Markdown()\n",
    "        \n",
    "    bttn.click(fn=run,\n",
    "               inputs=[task, inputs],\n",
    "               outputs=[inst_struc, inst])\n",
    "        \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
